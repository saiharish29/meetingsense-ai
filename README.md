<div align="center">

# ğŸ¯ MeetingSense AI

**Intelligent Meeting Analysis Engine â€” Self-Hosted & Open Source**

Convert meeting recordings and transcripts into structured summaries, decisions, action items, and clean transcripts using Google Gemini AI.

![Node.js](https://img.shields.io/badge/Node.js-22+-339933?logo=node.js&logoColor=white)
![Express](https://img.shields.io/badge/Express-4.x-000000?logo=express&logoColor=white)
![React](https://img.shields.io/badge/React-19-61DAFB?logo=react&logoColor=white)
![SQLite](https://img.shields.io/badge/SQLite-sql.js-003B57?logo=sqlite&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-blue)

</div>

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ™ï¸ **Dual-Channel Live Recording** | Records your mic (host) and system audio (participants) on separate channels for accurate speaker identification |
| ğŸ§ **Smart Speaker Separation** | Stereo recording: left channel = host, right channel = other participants. Gemini uses this for reliable speaker tagging |
| ğŸ“ **Audio/Video Upload** | Upload pre-recorded MP3, WAV, WebM, MP4, MOV files (up to 500MB) |
| ğŸ“ **Text Transcript Analysis** | Paste meeting transcripts or notes for instant structured analysis |
| ğŸ§  **AI-Powered Intelligence** | Powered by Google Gemini 2.5 Flash for accurate extraction of decisions, action items, and risks |
| ğŸ’¾ **Persistent Storage** | SQLite database stores all meetings, results, and uploaded files permanently |
| ğŸ” **Search & Filter** | Full-text search across meeting titles and summaries with status filtering |
| ğŸ“Š **Dashboard** | Overview statistics, recent meetings, and quick navigation |
| ğŸ“¤ **Export** | Download analysis results as Markdown files |
| ğŸ” **API Key Management** | Configure API key on first launch via UI â€” stored securely in local database |
| ğŸ‘¥ **Participant Photos** | Upload participant images to assist with speaker identification |
| ğŸ“± **Responsive UI** | Clean, modern interface built with React and Tailwind CSS |

## ğŸ™ï¸ Advanced Speaker Identification System

The biggest challenge in meeting transcription is **correctly identifying who said what**. MeetingSense AI solves this with a **5-signal identification system** that goes far beyond what a single audio stream can provide.

### The Problem
- Single-stream recording mixes all voices together â€” AI has to guess who is speaking
- Random screenshots are unreliable for speaker identification
- Voice-only identification fails when participants have similar accents or speaking styles
- The host's voice gets confused with participants in mixed audio

### The Solution: Multi-Signal Speaker Identification

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5 IDENTIFICATION SIGNALS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Signal 1: STEREO CHANNEL SEPARATION (Hardware-level)   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Your Mic â”‚ â†’ Left Ch    â”‚ System Audio     â”‚â†’ Right â”‚
â”‚  â”‚ (Host)   â”‚              â”‚ (Participants)   â”‚   Ch   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚  100% reliable: Left = Host, Right = Everyone else      â”‚
â”‚                                                         â”‚
â”‚  Signal 2: SPEAKER ACTIVITY TIMELINE                    â”‚
â”‚  Energy detection every 200ms on both channels:         â”‚
â”‚  [00:00-00:15] Host speaking â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘             â”‚
â”‚  [00:12-00:30] Participants  â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          â”‚
â”‚  [00:28-00:45] Host speaking â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          â”‚
â”‚                                                         â”‚
â”‚  Signal 3: PERIODIC SCREENSHOTS (every 30 seconds)      â”‚
â”‚  Meeting apps highlight the active speaker â€” Gemini     â”‚
â”‚  reads name labels and speaker indicators from these    â”‚
â”‚  screenshots and maps them to the audio timeline.       â”‚
â”‚                                                         â”‚
â”‚  Signal 4: PARTICIPANT ROSTER                           â”‚
â”‚  Names entered before recording â†’ used instead of       â”‚
â”‚  generic "Speaker B/C" labels                           â”‚
â”‚                                                         â”‚
â”‚  Signal 5: VOICE CONSISTENCY TRACKING                   â”‚
â”‚  Once a voice is matched to a name (via screenshots),   â”‚
â”‚  that assignment is maintained throughout.               â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How Signals Work Together (Example)

1. **At 02:15**, the system captures a screenshot from Zoom showing "Sarah Chen" highlighted as active speaker
2. **At 02:15**, the speaker activity timeline shows the RIGHT channel (participants) is active
3. **Therefore**: The voice on the right channel at 02:15 belongs to Sarah Chen
4. **Voice tracking**: The AI notes Sarah's voice characteristics and matches them to other segments
5. **At 05:30**, the same voice speaks again â†’ automatically tagged as Sarah Chen
6. **Meanwhile**: Any audio on the LEFT channel is always tagged as the host (e.g., Harish)

### Recording Flow

1. Enter your name and add other participants' names
2. Click **Start Recording** â†’ microphone captures your voice (left channel)
3. Share your meeting screen â†’ captures participants' audio (right channel) AND video for screenshots
4. System automatically captures screenshots every 30 seconds and builds a speech timeline
5. Click **Stop & Analyze** â†’ all signals are packaged and sent to Gemini with structured metadata

### What Gets Sent to Gemini

| Data | Purpose |
|------|---------|
| Merged stereo audio (WebM) | Left = host, Right = participants |
| Speaker activity timeline | Timestamped speech segments per channel |
| Screenshots (JPEG, every 30s) | Visual evidence of active speaker |
| Participant roster | Name mapping |
| Channel layout metadata | Instructions for the AI |

### Output: Speaker Identification Summary

Every analysis includes a transparency section showing how each speaker was identified:

| Speaker | Identification Method | Confidence |
|---------|----------------------|------------|
| Harish  | Host mic (left channel) | High |
| Sarah   | Screenshot at 02:15 + voice match | Medium |
| Speaker C | Voice differentiation only | Low |

## ğŸ“¦ Prerequisites

- **Node.js** 18+ (recommended: 22+)
- **Google Gemini API Key** â€” free tier available at [Google AI Studio](https://aistudio.google.com/apikey)

## ğŸš€ Quick Start

### 1. Clone the repository

```bash
git clone https://github.com/YOUR_USERNAME/meetingsense-ai.git
cd meetingsense-ai
```

### 2. Install dependencies

```bash
npm install
```

### 3. Start in development mode

```bash
npm run dev
```

This starts both:
- **Backend API** on `http://localhost:3001`
- **Frontend dev server** on `http://localhost:3000` (with hot reload)

### 4. Configure API Key

On first launch, the app will prompt you to enter your Google Gemini API key. The key is stored in the local SQLite database and never transmitted anywhere except to Google's API.

Alternatively, create `.env.local` with:

```bash
GEMINI_API_KEY=your_api_key_here
PORT=3001
UPLOAD_DIR=./uploads
MAX_FILE_SIZE_MB=500
```

## ğŸ­ Production Deployment

### Build and run

```bash
npm run build       # Build React frontend
npm start           # Start Express server (serves built frontend)
```

The production server runs on port 3001 by default and serves both the API and the static frontend.

### Docker (optional)

```dockerfile
FROM node:22-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --production
COPY . .
RUN npm run build
EXPOSE 3001
CMD ["npm", "start"]
```

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `GEMINI_API_KEY` | *(empty)* | Google Gemini API key (or configure via UI) |
| `PORT` | `3001` | Server port |
| `UPLOAD_DIR` | `./uploads` | Directory for uploaded audio/video files |
| `MAX_FILE_SIZE_MB` | `500` | Maximum upload file size in MB |

## ğŸ“ Project Structure

```
meetingsense-ai/
â”œâ”€â”€ server/                  # Express backend
â”‚   â”œâ”€â”€ index.js            # Server entry point
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ database.js     # SQLite (sql.js) initialization & helpers
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ meetings.js     # Meeting CRUD, upload, export endpoints
â”‚       â””â”€â”€ settings.js     # API key management endpoints
â”œâ”€â”€ src/                     # React frontend
â”‚   â”œâ”€â”€ main.tsx            # React entry point
â”‚   â”œâ”€â”€ App.tsx             # Main app with routing & API key gate
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ApiKeySetup.tsx # First-run API key configuration
â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx   # Dashboard with stats & recent meetings
â”‚   â”‚   â”œâ”€â”€ InputSection.tsx    # 3-mode input: Live Record, Upload, Text
â”‚   â”‚   â”œâ”€â”€ Layout.tsx      # Sidebar navigation layout
â”‚   â”‚   â”œâ”€â”€ MeetingDetailView.tsx # Single meeting view
â”‚   â”‚   â”œâ”€â”€ MeetingHistory.tsx   # Paginated meeting list
â”‚   â”‚   â”œâ”€â”€ ProcessingState.tsx  # Analysis progress indicator
â”‚   â”‚   â””â”€â”€ ResultView.tsx  # Tabbed analysis result display
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useMeetingRecorder.ts # Dual-channel recording hook (mic + system audio)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ api.ts          # Backend REST API client
â”‚   â”‚   â””â”€â”€ geminiService.ts # Gemini AI integration
â”‚   â”œâ”€â”€ constants.ts        # System prompt & config
â”‚   â””â”€â”€ types.ts            # TypeScript interfaces
â”œâ”€â”€ uploads/                 # Uploaded files (git-ignored)
â”œâ”€â”€ index.html              # HTML entry with Tailwind config
â”œâ”€â”€ vite.config.ts          # Vite configuration with API proxy
â”œâ”€â”€ tsconfig.json           # TypeScript configuration
â”œâ”€â”€ package.json            # Dependencies & scripts
â”œâ”€â”€ .env.local              # Environment variables (git-ignored)
â””â”€â”€ .gitignore
```

## ğŸ”Œ API Reference

### Settings

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/settings/api-key/status` | Check if API key is configured |
| `POST` | `/api/settings/api-key` | Save API key `{ apiKey: "..." }` |
| `POST` | `/api/settings/api-key/validate` | Validate an API key |
| `GET` | `/api/settings/api-key/active` | Get the active API key |

### Meetings

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/meetings` | List meetings (supports `?page=&limit=&search=&status=`) |
| `GET` | `/api/meetings/stats/overview` | Dashboard statistics |
| `GET` | `/api/meetings/:id` | Get meeting with full details |
| `POST` | `/api/meetings` | Create meeting (multipart: `file`, `text`, `participantImgs`) |
| `PUT` | `/api/meetings/:id/result` | Save analysis result |
| `PUT` | `/api/meetings/:id/status` | Update meeting status |
| `DELETE` | `/api/meetings/:id` | Delete meeting and associated files |
| `GET` | `/api/meetings/:id/export` | Export result as Markdown file |

### Health

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | Server & database health check |

## ğŸ—„ï¸ Database Schema

The SQLite database (`server/db/meetingsense.db`) contains:

- **meetings** â€” Core meeting records with title, status, duration, timestamps
- **meeting_inputs** â€” Input data (text transcripts, file references)
- **meeting_results** â€” AI analysis results (raw markdown, executive summary, metadata JSON)
- **meeting_participants** â€” Participant names and optional photo references
- **app_settings** â€” Application settings including API key storage

Reset the database:
```bash
npm run db:reset
```

## ğŸ”’ Security Notes

- API keys are stored in the local SQLite database file, **not** in plain text config files
- The database file is `.gitignored` and should never be committed
- Uploaded files are stored locally â€” ensure appropriate filesystem permissions
- In production, consider adding authentication middleware and HTTPS

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## ğŸ“„ License

This project is open source under the [MIT License](LICENSE).

## ğŸ™ Acknowledgements

- [Google Gemini AI](https://ai.google.dev/) â€” AI processing engine
- [sql.js](https://github.com/sql-js/sql.js/) â€” SQLite in JavaScript (no native deps)
- [Express](https://expressjs.com/) â€” Backend framework
- [React](https://react.dev/) â€” Frontend framework
- [Vite](https://vitejs.dev/) â€” Build tool
- [Tailwind CSS](https://tailwindcss.com/) â€” Styling
"# meetingsense-ai" 
